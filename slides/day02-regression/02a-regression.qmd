---
title: "Linear Regression"
author: 
  - "Author: Dr. Mine Dogucu"
  - "Co-author: Dr. Jessica Jaynes"
format: 
  revealjs:
    slide-number: true
    logo: "https://socaldatascience.github.io/bootcamp-materials-2022/img/socalds-logo.png"
    theme: ["slide-style.scss"]
    incremental: false
---



## Overview
- Review Linear Regression Concepts from your data science curses 
- Conditions for Least Squares Regression
- Multiple Linear Regression
- Model Evaluation 



```{r echo = FALSE, message = FALSE}
library(tidyverse)
library(openintro)
library(broom)
library(modelr)
theme_set(theme_gray(base_size = 18))
```


## Data `babies` in `openintro` package

```{r echo = FALSE}
glimpse(babies)
```

##  Baby Weights
:::: {.columns}
::: {.column width="40%"}
```{r eval = FALSE}
#| echo: true
ggplot(babies, 
       aes(x = gestation, y = bwt)) +
  geom_point()

```
:::

::: {.column width="60%"}
```{r echo = FALSE, fig.align='center', message = FALSE, fig.height= 6,warning = FALSE}
ggplot(babies, 
       aes(x = gestation, y = bwt)) +
  geom_point()
```
:::
::::

##  Baby Weights
:::: {.columns}
::: {.column width="40%"}
```{r eval = FALSE}
#| echo: true
ggplot(babies,
         aes(x = gestation, y = bwt)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) 

```
`lm` stands for linear model  
`se` stands for standard error
:::

::: {.column width="60%"}
```{r echo = FALSE, fig.align='center', message = FALSE, fig.height= 6,warning = FALSE}
ggplot(babies, 
       aes(x = gestation, y = bwt)) +
  geom_point()
```
:::
::::

## Numerical Response and Numerical Explanatory Variable

| Variable    | Variable Name | Type of Variable |
|-------------|-----------------|---------|
| Response (y)    | Birth weight | Numeric |
| Explanatory (x) | Gestation           | Numeric |


## Linear Equations Review
:::: {.columns}
::: {.column width="40%"}
Recall from your previous math classes

$y = mx + b$

where $m$ is the slope and $b$ is the y-intercept

e.g. $y = 2x -1$
:::

::: {.column width="60%"}
```{r echo = FALSE, fig.height = 5, message = FALSE}
x <- c(0, 1, 2, 3, 4, 5)
y <- c(-1, 1, 3, 5, 7, 9)

as.data.frame(x = x, y = y) %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  scale_y_continuous(breaks = c(-1, 1, 3, 5, 7, 9)) +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5)) +
  geom_smooth(method = "lm", se = FALSE)

```
Notice anything different between baby weights plot and this one?
:::
::::

## Equations
:::: {.columns}
::: {.column width="50%"}
**Math** class

$y = b + mx$

$b$ is y-intercept  
$m$ is slope  
:::

::: {.column width="50%"}
**Stats** class

$\mu_i = \beta_0 +\beta_1x_i + \epsilon_i$

$\beta_0$ is y-intercept  
$\beta_1$ is slope  
$\epsilon_i$ is error/residual  
$i = 1, 2, ...n$ identifier for each point
:::
::::

## Fitting a Linear Model in R
```{r}
#| echo: true
model_g <- lm(bwt ~ gestation, data = babies)
```
`lm` stands for linear model. We are fitting a linear regression model. Note that the variables are entered in y ~ x order.

## Fitting a Linear Model in R

```{r}
#| echo: true
broom::tidy(model_g)
```

$\hat{\mu_i} = \hat{\beta_0} + \hat{\beta_1} x_i$

$\hat {\text{bwt}_i} = \hat{\beta_0} + \hat{\beta_1} \text{ gestation}_i$

$\hat {\text{bwt}_i} = -10.1 + 0.464\text{ gestation}_i$


## Expected bwt for a baby with 300 days of gestation

$\hat {\text{bwt}_i} = -10.1 + 0.464\text{ gestation}_i$

$\hat {\text{bwt}} = -10.1 + 0.464 \times 300$

$\hat {\text{bwt}} = `r -10.1 + 0.464*300`$


For a baby with 300 days of gestation the expected birth weight is `r -10.1 + 0.464*300` ounces.

## Interpretation of estimates

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: false
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) 
    
```

$\hat{\beta_1} = 0.464$ which means for one unit(day) increase in gestation period the expected increase in birth weight is 0.464 ounces.
:::

::: {.column width="50%"}
```{r}
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlim(0, 360) +
  ylim(-10, 180) +
  geom_abline(slope = 0.459, intercept = -8.76)
  
  
```

$\hat{\beta_0} = -10.1$ which means for gestation period of 0 days the expected birth weight is -10.1 ounces!!!!!!!!
(does NOT make sense)
:::
::::

## Extrapolation
- There is no such thing as 0 days of gestation.
- Birth weight cannot possibly be -10.1 ounces.
- Extrapolation happens when we use a model outside the range of the x-values that are observed. After all, we cannot really know how the model behaves (e.g. may be non-linear) outside of the scope of what we have observed. 

## Baby number 148
:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: true
babies %>% 
  filter(case == 148) %>% 
  select(bwt, gestation)

```
:::

::: {.column width="50%"}
```{r echo = FALSE, message = FALSE, fig.height=5, warning = FALSE}

baby_148 <- subset(babies, case == 148)

babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(data = baby_148, color = "red")
```
:::
::::

## Baby #148
:::: {.columns}
::: {.column width="50%"}
**Expected**

$\hat \mu_{148} = \hat{\beta_0} + \hat{\beta_1}x_{148}$

$\hat \mu_{148} = -10.1 + 0.464\times300$

$\hat \mu_{148} = `r -10.1 + 0.464*300`$
:::

::: {.column width="50%"}
**Observed**

$$\mu_{148} = 160 $$
:::
::::

## Residual for `i = 148`
:::: {.columns}
::: {.column width="40%"}
```{r echo = FALSE, fig.align='center', message=FALSE, warning = FALSE, fig.height = 4}
babies %>% 
  ggplot() +
  aes(x = gestation, y = bwt) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point(data = baby_148, color = "red") +
  geom_segment(x = 300, xend = 300, y = 128.94, yend = 160, color = "red")
```
:::


::: {.column width="60%"}
$\mu_{148} = 160$

$\hat \mu_{148}$ = `r -10.1 + 0.464*300`

$e_{148} = \mu_{148} - \hat \mu_{148}$

$e_{148} =$ `r 160 -(-10.1 + 0.464*300)`
:::
::::

## Least Squares Regression 
The goal is to minimize 

$$e_1^2 + e_2^2 + ... + e_n^2$$

which can be rewritten as 

$$\sum_{i = 1}^n e_i^2$$

## Inference: Confidence Interval (theoretical)

```{r}
#| echo: true
confint(model_g)
```

Note that the 95% confidence interval for the slope does not contain zero and all the values in the interval are positive indicating a significant positive relationship between gestation and birth weight.

## Numerical Response and Categorical Explanatory Variable

| Variable    | Variable Name | Type of Variable |
|-------------|-----------------|---------|
| Response (y)    | Birth weight | Numeric |
| Explanatory (x) | Smoke           | Categorical |

## Notation

$\mu_i = \beta_0 +\beta_1x_i + \epsilon_i$

$\beta_0$ is y-intercept  
$\beta_1$ is slope  
$\epsilon_i$ is error/residual  
$i = 1, 2, ...n$ identifier for each point

## Fitting the model in R
```{r}
#| echo: true
model_s <- lm(bwt ~ smoke, data = babies)
tidy(model_s)
```
$\hat {\mu}_i = \hat{\beta_0} + \hat{\beta_1} x_i$

$\hat {\text{bwt}_i} = \hat{\beta_0} + \hat{\beta_1} \text{ smoke}_i$

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$


## Interpretation
:::: {.columns}
::: {.column width="50%"}
#### Expected bwt for a baby with a non-smoker mother

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$

$\hat {\text{bwt}_i} = 123 + (-8.94\times 0)$

$\hat {\text{bwt}_i} = 123$

$E[bwt_i | smoke_i = 0] = \hat{\beta_0}$
:::

::: {.column width="50%"}
#### Expected bwt for a baby with a smoker mother

$\hat {\text{bwt}_i} = 123 + (-8.94\text{ smoke}_i)$

$\hat {\text{bwt}_i} = 123 + (-8.94\times 1)$

$\hat {\text{bwt}_i} = 114.06$

$E[bwt_i | smoke_i = 1] = \hat{\beta_0} + \hat{\beta_1}$
:::
::::



## Evaluating Regression Models: Is the model fair?
- How was the data collected?
- By whom and for what purpose was the data collected?
- How might the results of the analysis, or the data collection itself, impact individuals and society?
- What biases might be baked into this analysis?

## Models are not always fair!
  - As recently as 2015, a major corporation reportedly utilized a model to evaluate applicants’ résumés for technical posts. They scrapped this model upon discovering that, by building this model using résumé data from its current technical employees (mostly men), it reinforced a preference for male job applicants (Dastin 2018).
  - Facial recognition models, increasingly used in police surveillance, are often built using image data of researchers that do not represent the whole of society. Thus, when applied in practice, misidentification is more common among people that are underrepresented in the research process. Given the severe consequences of misidentification, including false arrest, citizens are pushing back on the use of this technology in their communities (Harmon 2019).
  
## Evaluating Regression Models: How wrong is the model? 
- All models are wrong - Mainly, statistical models are idealistic representations of more complex realities. 
- Even so, good statistical models can still be useful and inform our understanding of the world’s complexities.
- The next question to ask in evaluating our model is not, is the model wrong, but how wrong is the model? 
- Specifically, to what extent do the assumptions behind our linear regression model match reality?

## Conditions for Least Squares Regression: LINE
<!--
https://openintro-ims.netlify.app/inf-model-slr.html#tech-cond-linmod
-->
- L: Linear model
- I: Independent observation
- N: Normality of residuals
- E: Equal/constant variability around the line for all values of the explanatory variable

## Linearity
- Probably the most important condition
- The data should have a linear trend
- If the data illustrate a non-linear trend, then more advanced regression methods could be considered

```{r  echo = FALSE, message = FALSE, fig.height = 5}
set.seed(84735)
x <- seq(-2, 2, by = 0.01)
y <- 4*x + 5 + rnorm(length(x), 0 , 1.5)

data_good <- data.frame(x = x, y = y) %>%   sample_n(50)

data_good %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)
```



## Linearity
A residual plot is one where the residuals are plotted against the explanatory variable. 
 
- Points in the residual plot must be randomly scattered, with no pattern, and "close" to 0.
```{r echo = FALSE, message = FALSE, fig.height = 4}

model_good <- lm(y ~ x, data = data_good)

data_good <- 
  data_good %>%
  sample_n(50) %>% 
  modelr::add_residuals(model_good)

data_good %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```


## Non-linear Trend
```{r  echo = FALSE, message = FALSE, fig.height = 5}
set.seed(84735)
x <- seq(-2, 2, by = 0.01)
y <- 3*x^2 + x + 5 + rnorm(length(x), 0 , 2)

data_bad<- data.frame(x = x, y = y) %>% sample_n(50)

data_bad %>% 
  ggplot() +
  aes(x = x, y = y) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  stat_function(fun = function(x)3*x^2 + x + 5 )
```

## Linear model not appropriate
```{r echo = FALSE, message = FALSE, fig.height = 4}
model_bad <- lm(y ~ x, data = data_bad)

data_bad <- 
  data_bad %>% 
  modelr::add_residuals(model_bad) 

data_bad %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```


## Independent Observations
- Cases must be independent of one-another
- Individuals must not be related (associated) to other individuals
- Harder to check because we need to know how the data were collected
- Be aware of data that come from sequential observations in time as they come with an underlying structure that needs to be considered when modeling - dependent data can bias results 



## Nearly Normal Residuals
- Residuals should be nearly normal 
- This condition can often be influenced by outliers
- While important, this condition can often be avoided through considering bootstrap procedures

```{r echo = FALSE, message = FALSE, fig.height = 5}
model_good <- lm(y ~ x, data = data_good)

data_good <- 
  data_good %>%
  sample_n(50) %>% 
  modelr::add_residuals(model_good) 

data_good %>% 
  ggplot(aes(x = resid)) +
  geom_density()

```


## Equal or Constant Variability
- The variability (scattered-ness) of the residual plot must be about the same throughout the plot.
- Data that do not satisfy this condition will potentially influence and mis-estimate the variability of the slope, impacting the inference
- A change in the variability as the explanatory variable increases means that predictions may not be reliable

```{r echo = FALSE, message = FALSE, fig.height = 4}
data_good %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

## Non-constant Variance
```{r echo = FALSE, message = FALSE, fig.height = 4}
data_bad %>% 
  ggplot(aes(x = x, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```

## When all technical conditions are met:
- The least squares regression model (and related inference)  has important extensions (which are not trivial to implement with bootstrapping and randomization tests). 
- In particular, random effects models, repeated measures, and interaction are all linear model extensions which require the above technical conditions.


## Verifying Conditions for the Baby Weights Example

## Linearity: Using scattered plot
```{r}
#| echo: true
babies %>% 
  ggplot (aes(x = gestation, y = bwt)) +
  geom_point()
```

## Linearity and constant variance: Using residual plot
- First, add residuals to your data. Next, plot the explanatory variable against the residuals and add a line through `y = 0`
```{r}
#| echo: true
babies <- babies %>% 
  modelr::add_residuals(model_g)

ggplot(babies, aes(x = gestation, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0)
```



## Normality of residuals
```{r}
#| echo: true
model_g %>% 
  ggplot(aes(x = .resid)) +
  geom_density()
```

## Independence

- In the description of the dataset it says a study considered all pregnancies between 1960 and 1967 among women in the Kaiser Foundation Health Plan in the San Francisco East Bay area.
- It is possible that babies born in the same hospital may have similar birth weight. 
- Correlated data examples: patients within hospitals, students within schools, people within neighborhoods, time-series data. 

## Multiple Linear Regression

| Variable    | Variable Name | Type of Variable |
|-------------|-----------------|---------|
| Response (y)    | Birth weight | Numeric |
| Explanatory (x1) | Smoke           | Categorical |
| Explanatory (x2) | Gestation           | Numeric |

## Notation for Multiple Linear Regression

$\mu_i = \beta_0 +\beta_1x_{1i}  + \beta_2x_{2i} + \epsilon_i$

$\beta_0$ is intercept  
$\beta_1$ is the slope for gestation   
$\beta_2$ is the slope for smoke 
$\epsilon_i$ is error/residual  
$i = 1, 2, ...n$ identifier for each point

## Multiple Linear Regression in R
```{r}
model_gs <- lm(bwt ~ gestation + smoke, data = babies)
tidy(model_gs)
```

Expected birth weight for a baby who had 280 days of gestation with a smoker mother

$\hat {\text{bwt}_i} = b_0 + b_1 \text{ gestation}_i + b_2 \text{ smoke}_i$

$\hat {\text{bwt}_i} = -0.932 + (0.443 \times 280) + (-8.09 \times 1)$


## Model Evaluation: $R^2$

```{r}
#| echo: true
glance(model_gs)$r.squared
```

21% of the variation in birth weight is explained by gestation. Higher values of R squared is preferred.


## Multiple Linear Regression with Three Predictors
```{r}
#| echo: true
model_gsa <- lm(bwt ~ gestation + smoke + age, data = babies)
```

## Comparing Models: Single Predictor
```{r}
#| echo: true
babies %>% 
  add_predictions(model_g) %>% 
  add_residuals(model_g) %>% 
  select(bwt, pred, resid)
```

## Comparing Models: Three Predictors
```{r}
#| echo: true
babies %>% 
  add_predictions(model_gsa) %>% 
  add_residuals(model_gsa) %>% 
  select(bwt, pred, resid)
```

## Root Mean Square Error

$RMSE = \sqrt{\frac{\Sigma_{i=1}^n(y_i-\hat y_i)^2}{n}}$

```{r}
#| echo: true
modelr::rmse(model_gsa, babies)
```

```{r}
#| echo: true
modelr::rmse(model_g, babies)
```
Can we keep adding all the variables and try to get an EXCELLENT model fit?

## Overfitting

- We are fitting the model to sample data.

- Our goal is to understand the population data.

- If we make our model too perfect for our sample data, the model may not perform as well with other sample data from the population.

- In this case we would be overfitting the data.

- We can use **model validation** techniques.

## Modeling Overfitting: Cross-validation
Data sets are often divided into two sets:

- Training: Set of data on which you build your model
- Testing: After your model is built, this set of data is used to test it by evaluating it against data that it has not previously seen.

"Perhaps the most elementary mistake in predictive analytics is to overfit your model to the training data, only to see it later perform miserably on the testing set."

## Splitting the Data (Train vs. Test)

```{r message=FALSE}
#| echo: true
set.seed(12345)
babies_split <- rsample::initial_split(babies) ## 75% to 25% split
```

```{r}
#| echo: true
babies_train <- rsample::training(babies_split)
dim(babies_train)
```


```{r}
#| echo: true
babies_test <- rsample::testing(babies_split)
dim(babies_test)
```


## Train vs. Test
```{r}
#| echo: true
model_gsa_train <- lm(bwt ~ gestation + smoke + age, data = babies_train)
model_gsa_test <- lm(bwt ~ gestation + smoke + age, data = babies_test)
```

## Training Data
```{r}
#| echo: true
glance(model_gsa_train)
modelr::rmse(model_gsa_train, babies_train)

```

## Testing Data
```{r}
#| echo: true
glance(model_gsa_test)
modelr::rmse(model_gsa_test, babies_test)
```
